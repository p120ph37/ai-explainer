# Frontier AI Explainer â€” Design Philosophy

## Mission

Create an interactive learning tool that helps non-technical users understand the **mechanics and architecture** of frontier AI technologyâ€”the "how" and "why"â€”not just the "what."

The goal is to enable users to:
- Set realistic expectations for AI capabilities and limitations
- Use AI tools more effectively through understanding
- Develop intuition for AI behavior through exposure to underlying concepts
- Navigate the AI ecosystem with confidence

## Core Principles

### 1. Cognitive Load Management

The explainer must respect the user's cognitive bandwidth. We anticipate users may be encountering many concepts entirely de novo.

**Rules:**
- Each content node must be understandable using *only* concepts already explained in the path that led to it
- New concepts mentioned but not yet explained must be **optionally opaque**â€”the surrounding material makes sense without drilling into them
- Unexplained concepts are hyperlinked, inviting exploration but not requiring it
- Each step should feel complete and satisfying on its own

**Anti-patterns:**
- Assuming prerequisite knowledge not established in the path
- Requiring forward-references to understand current content
- Dense walls of interconnected new terminology

### 2. Progressive Disclosure

Information depth is user-controlled. The default view shows high-level, relatable concepts. Detail is available on demand.

**Implementation:**
- Expandable/collapsible sections for deeper detail
- Layered annotations on diagrams (show more on click/hover)
- "Aside" blocks for tangential but interesting details
- Clear visual hierarchy distinguishing summary from detail

### 3. Horizontal vs. Vertical Navigation

Unlike TV Tropes (primarily horizontal/lateral navigation to related concepts), this explainer emphasizes **vertical navigation** (shallow â†’ deep understanding).

However, we do support horizontal navigation for:
- Alternative explanations/framings of the same concept
- Related concepts at the same abstraction level
- Real-world examples and applications

**Navigation affordances:**
- **Downward:** "How does this work?" / "What's inside?"
- **Upward:** "Where does this fit?" / "Why does this matter?"
- **Lateral:** "See also" / "Compare to" / "Used in"

### 4. Recognition Hooks & Immediate Applicability

Each node should connect to something the user already knows or can immediately observe:
- References to familiar AI tools (ChatGPT, Claude, etc.)
- "Try this" prompts they can test immediately
- "You'll notice this when..." observations
- Analogies to everyday phenomena

### 5. Credibility Through Citations

All factual claims should be traceable to sources:
- Primary sources (research papers, technical docs)
- Reputable secondary sources (3Blue1Brown, Veritasium, Anthropic blog)

**Link annotations:**
- ğŸ“„ Technical/research paper (deep dive, for fact-checking)
- ğŸ¬ Video explainer (accessible, different perspective)
- ğŸ”— External article (supplementary reading)
- ğŸ“– Official documentation (authoritative reference)

## Content Structure

### Node Anatomy

Each content node consists of:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Title                                   â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ One-sentence summary (the "TLDR")       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚ Core explanation                        â”‚
â”‚ - Uses only established concepts        â”‚
â”‚ - Hyperlinks new terms (don't require   â”‚
â”‚   clicking to understand)               â”‚
â”‚ - 2-4 paragraphs typical                â”‚
â”‚                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Expandable: Deeper Detail]             â”‚
â”‚ [Expandable: Technical Specifics]       â”‚
â”‚ [Expandable: Historical Context]        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Interactive element (if applicable)     â”‚
â”‚ - Visualization                         â”‚
â”‚ - Mini-simulation                       â”‚
â”‚ - Annotatable diagram                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Recognition hook / Try this             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Navigation                              â”‚
â”‚ â†“ Deeper: [links to child concepts]     â”‚
â”‚ â†” Related: [lateral links]              â”‚
â”‚ ğŸ“š Sources: [citations]                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Topic Hierarchy (Initial Scope)

```
Entry Point: "What is an LLM?"
â”‚
â”œâ”€â”€ The Big Picture
â”‚   â”œâ”€â”€ What AI is (and isn't)
â”‚   â”œâ”€â”€ Machine Learning vs. Traditional Programming
â”‚   â””â”€â”€ Why "Large" and why "Language"
â”‚
â”œâ”€â”€ Inside the Black Box
â”‚   â”œâ”€â”€ Tokens: The Atoms of Text
â”‚   â”œâ”€â”€ Embeddings: Meaning as Geometry
â”‚   â”œâ”€â”€ Attention: How Context Flows
â”‚   â”œâ”€â”€ Transformers: The Architecture
â”‚   â””â”€â”€ Parameters: Where Knowledge Lives
â”‚
â”œâ”€â”€ Training: How Models Learn
â”‚   â”œâ”€â”€ Datasets: Learning from the Internet
â”‚   â”œâ”€â”€ Pre-training: Pattern Absorption
â”‚   â”œâ”€â”€ Fine-tuning: Specialization
â”‚   â”œâ”€â”€ RLHF: Learning from Human Preferences
â”‚   â””â”€â”€ Emergent Capabilities
â”‚
â”œâ”€â”€ Using Models: The API Layer
â”‚   â”œâ”€â”€ Prompts and Completions
â”‚   â”œâ”€â”€ Context Windows
â”‚   â”œâ”€â”€ Temperature and Sampling
â”‚   â”œâ”€â”€ System Prompts and Personas
â”‚   â””â”€â”€ Tool Use and Function Calling
â”‚
â”œâ”€â”€ The Ecosystem
â”‚   â”œâ”€â”€ Model Providers (OpenAI, Anthropic, etc.)
â”‚   â”œâ”€â”€ Open vs. Closed Models
â”‚   â”œâ”€â”€ RAG: Retrieval-Augmented Generation
â”‚   â”œâ”€â”€ Agents and Autonomous Systems
â”‚   â””â”€â”€ Multimodal Models
â”‚
â””â”€â”€ Limitations and Misconceptions
    â”œâ”€â”€ Hallucinations: Why Models Make Things Up
    â”œâ”€â”€ The Knowledge Cutoff
    â”œâ”€â”€ What "Understanding" Means (and Doesn't)
    â””â”€â”€ Alignment and Safety
```

## Technical Implementation

### Stack
- **Runtime/Bundler:** Bun
- **UI:** Preact (lightweight React alternative, ~3KB)
- **Styling:** CSS with custom properties, CSS layers
- **Hosting:** GitHub Pages (static output)
- **Content:** TypeScript modules with JSX for rich content

### Content as Code

Content nodes are TypeScript/TSX files that export structured data:
- Enables type safety and IDE support
- Allows embedding interactive components directly
- Supports programmatic navigation graph generation
- Easy to refactor and reorganize

### Code Splitting

The bundled output uses dynamic imports to:
- Load only the content nodes needed for the current path
- Prefetch likely next nodes for smooth navigation
- Keep initial load minimal

### Responsive Design

- Mobile-first CSS
- Touch-friendly navigation
- Collapsible sections work well on small screens
- Visualizations degrade gracefully (simpler on mobile)

